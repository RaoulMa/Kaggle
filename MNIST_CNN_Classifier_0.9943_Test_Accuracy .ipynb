{
  "cells": [
    {
      "metadata": {
        "_uuid": "8abac6e9d07e55338b420f9789904bc957f8fa0c",
        "_cell_guid": "ae26a5da-aab9-47a2-b7dd-644778615a16"
      },
      "cell_type": "markdown",
      "source": "**Author:** Raoul Malm  \n\n**Abstract:** CNN classifier for handwritten digits of the MNIST dataset. The dataset consists of 42000 images of size 28x28 = 784 pixels (one color number) including the corresponding labels from 0,..,9. The basic architecture of the NN is given by,\n\n- Layer: input = [.,784]\n- Layer: Conv1 -> ReLu -> MaxPool: [.,14,14,36] \n- Layer: Conv2 -> ReLu -> MaxPool: [.,7,7,36]\n- Layer: Conv3 -> ReLu -> MaxPool: [.,4,4,36]\n- Layer: FC -> ReLu: [.,576]\n- Layer: FC -> ReLu: [.,10]\n\nbut can be easily modified in the code below.  \n\n**Outline:**\n1. Libraries and settings\n2. Analyze and manipulate data\n3. Build CNN graph in tensorflow\n4. Train and validate CNN graph\n5. Predict and submit test results\n\n**Results:** \n- Using a split of 95%/5% on the labeled data this implementation, trained on 40.000 original and 240.000 augmented training images for 3 epochs with suitable hyperparameters, achieves a 99.60% accuracy on the validation set of 2000 images. This takes for the kaggle hardware roughly 30 minutes.\n- Using all labeled data this implementation, trained on 42.000 original and 252.000 augmented training images for 3 epochs, achieves roughly a 99.43% accuracy on the public test set. This takes for the kaggle hardware roughly 30 minutes. \n\n**Reference:** [TensorFlow deep NN by Kirill Kliavin](http://https://www.kaggle.com/kakauandme/tensorflow-deep-nn?scriptVersionId=164725)\n\n\n## 1. Libraries and settings\n- import libraries\n- set validation set size\n- set CNN architecture: number and size of filters, number of neurons"
    },
    {
      "metadata": {
        "_uuid": "420cf9cf5d64f79d38869ba265edfd759f1e4865",
        "collapsed": true,
        "_cell_guid": "8fc7ff0a-f896-485a-9628-2f4c639942d0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm # cm = colormap\nimport tensorflow as tf\n%matplotlib inline\nimport os;\nimport itertools\nfrom datetime import datetime\nimport cv2 \n\ndir_logs = os.getcwd()+'/logs'; # directory to save models\nval_set_size = 0; # validation set size (default = 2000)\ns_f_conv1 = 3; # filter size of first convolution layer (default = 3)\nn_f_conv1 = 36; # number of features of first convolution layer (default = 36)\ns_f_conv2 = 3; # filter size of second convolution layer (default = 3)\nn_f_conv2 = 36; # number of features of second convolution layer (default = 36)\ns_f_conv3 = 3; # filter size of third convolution layer (default = 3)\nn_f_conv3 = 36; # number of features of third convolution layer (default = 36)\nn_n_fc1 = 576; # number of neurons of first fully connected layer (default = 576)\n#tf.set_random_seed(10); # for reproducible results\n\n#display parent directory and working directory\nprint(os.path.dirname(os.getcwd())+':', os.listdir(os.path.dirname(os.getcwd())));\nprint(os.getcwd()+':', os.listdir(os.getcwd()));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15744e6161356ffdfaba3da0eb55c469f187a246",
        "_cell_guid": "e1bd0032-cf12-45cd-840d-bbe8b36b8383"
      },
      "cell_type": "markdown",
      "source": "## 2. Analze and manipulate data\n- load and check data\n- normalize data and split into training and validation sets\n- augment training data"
    },
    {
      "metadata": {
        "_uuid": "cd465ec1f9f87cfe2432ad669e81bf142aac1352",
        "collapsed": true,
        "_cell_guid": "1c4dc51a-add1-410d-a586-58e934d0afd5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## load and check data\n\nif os.path.isfile('../input/train.csv'):\n    data = pd.read_csv('../input/train.csv') # on kaggle \n    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\nelif os.path.isfile('data/train.csv'):\n    data = pd.read_csv('data/train.csv') # on local environment\n    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\nelse:\n    print('Error: train.csv not found')\n\n# basic info about data\nprint('')\nprint(data.info())\n\n# no missing values\nprint('')\nprint(data.isnull().any().describe())\n\n# 10 different labels ranging from 0 to 9\nprint('')\nprint('distinct labels ', data['label'].unique())\n\n# data are approximately balanced (less often occurs 5, most often 1)\nprint('')\nprint(data['label'].value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4021b771e17a5f9787c9b71ad5c6733c92ec860c",
        "collapsed": true,
        "_cell_guid": "64f637d5-34c4-49ea-a743-fbc1b2cd917b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## normalize data and split into training and validation sets\n\n# extract and normalize images\nimages = data.iloc[:,1:].values.reshape(-1,28,28,1) # (42000,28,28,1) array\nimages = images.astype(np.float) # convert from int64 to float32\nimages = np.multiply(images, 1.0 / 255.0) # convert from [0:255] to [0.0:1.0]\nimage_size = 784\nimage_width = image_height = 28\n#image_size = images.shape[1] # = 784\n#image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8) # = 28\n\n# extract image labels\nlabels_flat = data.iloc[:,0].values # (42000,1) array\nlabels_count = np.unique(labels_flat).shape[0]; # number of different labels = 10\n\n#plot some images and labels\nplt.figure(figsize=(15,2))\nfor i in range(0,10):\n    plt.subplot(2,10,1+i)\n    plt.title(labels_flat[i])\n    plt.imshow(images[i].reshape(28,28),cmap=cm.binary)\n    \n# convert class labels from scalars to one-hot vectors e.g. 1 => [0 1 0 0 0 0 0 0 0 0]\ndef dense_to_one_hot(labels_dense, num_classes):\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n# labels in one hot representation\nlabels = dense_to_one_hot(labels_flat, labels_count).astype(np.uint8)\n#labels = labels.astype(np.uint8)\n\n# split data into training & validation\nperm_array = np.arange(images.shape[0]) \nnp.random.shuffle(perm_array) # shuffle train/valid sets\ntrain_images = images[perm_array[val_set_size:]]\ntrain_labels = labels[perm_array[val_set_size:]]\nval_images = images[perm_array[:val_set_size]]\nval_labels = labels[perm_array[:val_set_size]]\n\nprint('images{0},'.format(images.shape))\nprint('labels_flat{0}'.format(labels_flat.shape))\nprint('train_images{0}'.format(train_images.shape))\nprint('train_labels{0}'.format(train_labels.shape))\nprint('val_images{0}'.format(val_images.shape))\nprint('val_labels{0}'.format(val_labels.shape))\nprint ('image_size = {0}, image_width = {1}, image_height = {2}, labels_count = {3}'.format(\n    image_size,image_width,image_height,labels_count))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6ee73ea0669ef03051cdbebf01c7626f56ab91d0",
        "_cell_guid": "5ac987f0-95f7-4a32-ae87-e3fb8b362bff",
        "collapsed": true,
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "## augment training data\n\n# function to generate new images by rotation, translation, zooming \ndef generate_image(img, op = -1):\n    img_new = img;\n    #randomize operation\n    if op == -1:\n        op = np.random.randint(6)\n    \n    # rotation\n    if op == 0:\n        angle = 10 - 20*np.random.randint(2) # +- 10 degrees\n        M_rotate = cv2.getRotationMatrix2D((14,14),angle,1)\n        img_new = cv2.warpAffine(img,M_rotate,(28,28))\n\n    # translation horizontal, vertical\n    if op == 1:\n        shift_horizontal = 2 - 4*np.random.randint(2) # +- 2 pixels\n        shift_vertical = 0;\n        M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\n        img_new = cv2.warpAffine(img,M_translate,(28,28))\n   \n    # translation vertical\n    if op == 2:\n        shift_horizontal = 0;\n        shift_vertical = 2 - 4*np.random.randint(2) # +- 2 pixels\n        M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\n        img_new = cv2.warpAffine(img,M_translate,(28,28))\n \n    # translation diagonal positive\n    if op == 3:\n        shift_diagonal = 2 - 4*np.random.randint(2) # +- 2 pixels\n        M_translate = np.float32([[1,0,shift_diagonal],[0,1,shift_diagonal]])\n        img_new = cv2.warpAffine(img,M_translate,(28,28))\n    \n    # translation diagonal negative\n    if op == 4:\n        shift_diagonal = 2 - 4*np.random.randint(2) # +- 2 pixels\n        M_translate = np.float32([[1,0,shift_diagonal],[0,1,-shift_diagonal]])\n        img_new = cv2.warpAffine(img,M_translate,(28,28))\n   \n    # zoom\n    if op == 5:\n        rd = np.random.randint(2);\n        if rd == 0:\n            # zoom in\n            img_new = cv2.resize(img, (32,32)) # scale by 2 pixels in each direction\n            img_new = img_new[2:-2,2:-2] # crop\n        else:\n            # zoom out\n            img_new = cv2.resize(img, (24,24)) # scale by 2 pixels in each direction\n            img_new = cv2.copyMakeBorder(img_new,2,2,2,2,cv2.BORDER_CONSTANT,value=0.0) # zero padding\n            \n    return img_new.reshape(28,28,1).astype(np.float)\n\ndef augment_data(x_data, y_data):\n    x_data_generated = []; # list for generated images\n    y_data_generated = []; # list for labels of generated images\n    \n    for i in range(train_images.shape[0]):\n        # x_data_generated.append(generate_image(x_data[i]))\n        # y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],0)) # rotation\n        y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],1)) # translation horizontal\n        y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],2)) # translation vertical\n        y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],3)) # translation diagonal positive\n        y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],4)) # translation diagonal negative\n        y_data_generated.append(y_data[i])\n        x_data_generated.append(generate_image(x_data[i],5)) # zooming\n        y_data_generated.append(y_data[i])\n\n        \n    x_data_generated = np.array(x_data_generated);\n    y_data_generated = np.array(y_data_generated);\n    \n    #print('x_data_generated.shape = ', x_data_generated.shape)\n    #print('y_data_generated.shape = ', y_data_generated.shape)\n    \n    x_data_augmented = np.concatenate((x_data, x_data_generated),axis=0)\n    y_data_augmented = np.concatenate((y_data, y_data_generated),axis=0)\n    \n    return x_data_augmented, y_data_augmented\n\n# augment data\ntrain_images, train_labels = augment_data(train_images, train_labels)\n\nprint('Data augmentation:')\nprint('train_images.shape',train_images.shape)\nprint('train_labels.shape',train_labels.shape)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "245df7c4c7e6e8f18f26ab255ec3ec7b2caa2543",
        "collapsed": true,
        "_cell_guid": "e29198b0-f618-44c6-9e57-254195830eee",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## check augmented data\nplt.figure(figsize=(15,2))\nplt.subplot(2,10,1)\nplt.title(train_labels[0+11])\nplt.imshow(train_images[0+11].reshape(28,28),cmap=cm.binary) \nplt.subplot(2,10,2)\nplt.title(train_labels[40000+11])\nplt.imshow(train_images[40000+11].reshape(28,28),cmap=cm.binary) \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca11a3d68a3411473d87b761e68f558f516020aa",
        "collapsed": true,
        "_cell_guid": "0ba584ed-9ba9-4322-953b-65aa2e4c6675",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## check data augmentation\nimg = images[6].reshape(28,28)\nplt.figure(figsize=(15,2))\nfor i in range(0,10):\n    plt.subplot(2,10,1+i)\n    plt.title(labels_flat[i])\n    if i == 0:\n        plt.imshow(img,cmap=cm.binary)\n    else:\n        plt.imshow(generate_image(img).reshape(28,28),cmap=cm.binary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "21a49993c6e32b06ca3cb76a76d4c688ac15a161",
        "_cell_guid": "1eff9850-60ba-4f02-8de7-941865a8d91c"
      },
      "cell_type": "markdown",
      "source": "## 3. Build TensorFlow graph\n- create the neural net architecture with convolutional and fully connected layers"
    },
    {
      "metadata": {
        "_uuid": "57d7213a23ff15c677946c5ee3c81b04579c87ec",
        "collapsed": true,
        "_cell_guid": "d3bedd5b-c40d-46a7-8e7e-19af7f2a5773",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## Build the TensorFlow Graph\n\n#tf.set_random_seed(1)\n#np.random.seed(1)\n\n# weight and bias initialization\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape) #  positive bias\n    return tf.Variable(initial)\n\n# 2D convolution\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n# max pooling\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n# variables for input and output \nx = tf.placeholder('float', shape=[None, image_height, image_width, 1])\ny_ = tf.placeholder('float', shape=[None, labels_count])\n\n# 1. layer: convolution + max pooling\n#image = tf.reshape(x, [-1,28,28,1]) # (.,784) => (.,28,28,1)\nW_conv1 = weight_variable([s_f_conv1, s_f_conv1, 1, n_f_conv1]) # (5,5,1,32)\nb_conv1 = bias_variable([n_f_conv1]) # (32)\nh_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1) # => (.,28,28,32)\nh_pool1 = max_pool_2x2(h_conv1) # => (.,14,14,32)\n\n# 2. layer: convolution + max pooling\nW_conv2 = weight_variable([s_f_conv2, s_f_conv2, n_f_conv1, n_f_conv2])\nb_conv2 = bias_variable([n_f_conv2])\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # => (.,14,14,32)\nh_pool2 = max_pool_2x2(h_conv2) # => (.,7,7,32)\n\n# 3. layer: convolution + max pooling\nW_conv3 = weight_variable([s_f_conv3, s_f_conv3, n_f_conv2, n_f_conv3])\nb_conv3 = bias_variable([n_f_conv3])\nh_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3) # => (.,7,7,32)\nh_pool3 = max_pool_2x2(h_conv3) # => (.,4,4,32)\n\n# 5.layer: fully connected\nW_fc1 = weight_variable([4*4*n_f_conv3,n_n_fc1]) # (4*4*32, 1024)\nb_fc1 = bias_variable([n_n_fc1]) # (1024)\nh_pool3_flat = tf.reshape(h_pool3, [-1,4*4*n_f_conv3]) # (.,4,4,32) => (.,1024)\nh_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1) # => (.,1024)\n\n# dropout\ntf_keep_prob = tf.placeholder('float')\nh_fc1_drop = tf.nn.dropout(h_fc1, tf_keep_prob)\n\n# 4.layer: fully connected\nW_fc2 = weight_variable([n_n_fc1, labels_count])\nb_fc2 = bias_variable([labels_count])\ny = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 # => (.,10)\n\n# cost function\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n# optimisation function\nglobal_step = tf.Variable(0, trainable=False)\ntf_learn_rate = tf.placeholder(dtype='float', name=\"tf_learn_rate\")\ntrain_step = tf.train.AdamOptimizer(tf_learn_rate).minimize(cross_entropy)\n\n# evaluation\ncorrect_prediction = tf.equal(tf.argmax(tf.nn.softmax(y),1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n\n# prediction function\npredict = tf.argmax(tf.nn.softmax(y),1) # [0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n\n# function: to get the next mini batch\ndef next_batch(batch_size):\n    global train_images, train_labels, index_in_epoch, perm_array, train_set_size;\n    assert batch_size <= train_set_size\n \n    start = index_in_epoch\n    index_in_epoch += batch_size\n    \n    if index_in_epoch > train_set_size:\n        np.random.shuffle(perm_array) # shuffle data\n        start = 0 # start next epoch\n        index_in_epoch = batch_size\n        \n    end = index_in_epoch\n    return train_images[perm_array[start:end]], train_labels[perm_array[start:end]]\n\nprint('# weights = ', s_f_conv1**2*n_f_conv1 + s_f_conv2**2*n_f_conv1*n_f_conv2 + \n      s_f_conv3**2*n_f_conv2*n_f_conv3 + 4*4*n_f_conv3*n_n_fc1 + n_n_fc1*10)\nprint('# biases = ', n_f_conv1 + n_f_conv2 + n_f_conv3 + n_n_fc1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "180614885e56beb180592796a1267c0fbcab30ac",
        "_cell_guid": "e2b7c61e-88bb-40dd-bde0-5ec1977d8365"
      },
      "cell_type": "markdown",
      "source": "## 4. Training and Validation\n- train the model\n- visualize the results, the weights, the activations\n- tune the hyperparameters"
    },
    {
      "metadata": {
        "_uuid": "767d03d478b0a3a5a6cf97751db20ddd054de78c",
        "collapsed": true,
        "_cell_guid": "96416e2d-9d37-408a-b690-812a7328e7fb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## set parameters\n\nsess = tf.InteractiveSession() # start TensorFlow session\nsess.run(tf.global_variables_initializer()) # initialize global variables\n\n# variables and parameters\ntrain_set_size = train_images.shape[0]\nperm_array = np.arange(train_set_size)\nnp.random.shuffle(perm_array)\nindex_in_epoch = 0;\ntrain_acc, val_acc, train_loss, val_loss = np.array([]),np.array([]),np.array([]),np.array([]);  \nlog_step = 100; # log results each step\nepoch_no = 3; # no of epochs \n\n# test hyperparameters\nmb_size_range = [50]; # mini batch size\nkeep_prob_range = [0.33]; # dropout regularization with keeping probability\nlearn_rate_range = [10*1e-4, 7.5*1e-4, 5*1e-4, 2.5*1e-4, 1*1e-4, 1*1e-4, 1*1e-4, 0.75*1e-4, \n                    0.5*1e-4, 0.25*1e-4, 0.1*1e-4, 0.1*1e-4, 0.075*1e-4, 0.050*1e-4,\n                    0.025*1e-4, 0.01*1e-4, 0.0075*1e-4, 0.0050*1e-4, 0.0025*1e-4, 0.001*1e-4];\nlearn_rate_step = 0.3;",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "98c599d07113cfa8bfee30244e31655400737184",
        "collapsed": true,
        "_cell_guid": "2ca5e137-2767-4261-ac20-65d86042e856",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## train the TensorFlow graph\n\nstart = datetime.now();\n\nfor mb_size,keep_prob in itertools.product(mb_size_range,keep_prob_range):\n    \n    mb_no = int(np.floor(epoch_no*train_set_size/mb_size)); # no of mini batches\n    learn_rate_step = int(np.floor(learn_rate_step*train_set_size/mb_size)); # steps in batches\n    print('epoch_no = %.0f, mb_size = %.0f, keep_prob = %.2f'%(epoch_no,mb_size,keep_prob))\n    learn_rate_pos = -1;\n    \n    for i in range(0,mb_no+1):\n        \n        if (i%learn_rate_step == 0) and ((learn_rate_pos+1) < len(learn_rate_range)):\n            learn_rate_pos+=1;\n            learn_rate = learn_rate_range[learn_rate_pos]  # adapt learn_rate\n            print('set current learn rate to: %.6f'%learn_rate)\n        \n        #learn_rate = 0.001*1e-4;\n        \n        batch_xs, batch_ys = next_batch(mb_size) #get new batch\n        \n        if i > 0:\n             sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, \n                                                tf_keep_prob: keep_prob, \n                                                tf_learn_rate: learn_rate})\n        if i%log_step == 0 or i == mb_no:\n            \n            if val_set_size > 0:\n                train_loss = np.append(train_loss, sess.run(cross_entropy, \n                                feed_dict={x:train_images[0:val_set_size], \n                                           y_:train_labels[0:val_set_size], \n                                           tf_keep_prob:1.0}));\n                \n                train_acc = np.append(train_acc, \n                                accuracy.eval(feed_dict={x:train_images[0:val_set_size], \n                                                         y_:train_labels[0:val_set_size], \n                                                         tf_keep_prob:1.0}));      \n                \n                val_loss = np.append(val_loss, sess.run(cross_entropy, \n                                feed_dict={x:val_images, y_: val_labels, tf_keep_prob: 1.0}));\n                \n                val_acc = np.append(val_acc, accuracy.eval(feed_dict={x: val_images, \n                                                            y_: val_labels,tf_keep_prob: 1.0}));                                  \n            else:\n                train_loss = np.append(train_loss, sess.run(cross_entropy, \n                                    feed_dict={x:train_images[0:2000], \n                                        y_:train_labels[0:2000], tf_keep_prob:1.0}));\n                \n                train_acc = np.append(train_acc, accuracy.eval(feed_dict={x:train_images[0:2000], \n                                                                          y_:train_labels[0:2000], \n                                                                          tf_keep_prob:1.0}));      \n                \n                val_loss = [0]; val_acc = [0];\n                \n            print('%.2f epoch: train/val loss = %.4f/%.4f , train/val acc = %.4f/%.4f'\n                  %(i*mb_size/train_set_size,train_loss[-1],val_loss[-1],train_acc[-1], \n                    val_acc[-1]));\n\n    # save model\n    #if not os.path.exists(dir_logs): # check if directory for logs exists\n    #    os.makedirs(dir_logs)\n    #np.savez(dir_logs+'/model.npz', \n    #        learn_rate = learn_rate, keep_prob = keep_prob, mb_size = mb_size, log_step = log_step,\n    #        W_conv1 = np.asarray(W_conv1.eval()), b_conv1 = np.asarray(b_conv1.eval()), W_conv2 = np.asarray(W_conv2.eval()),\n    #        b_conv2 = np.asarray(b_conv2.eval()), W_fc1 = np.asarray(W_fc1.eval()), b_fc1 = np.asarray(b_fc1.eval()),\n    #        W_fc2 = np.asarray(W_fc2.eval()), b_fc2 = np.asarray(b_fc2.eval()),\n    #        train_loss = train_loss, val_loss = val_loss, train_acc = train_acc,\n    #        val_acc = val_acc, val_loss_final = val_loss_final, val_acc_final = val_acc_final);\n\n    #close session\n    #sess.close();\n\nprint('training time: ', datetime.now()-start)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d8fd8ba7e1bd518979de953f41594fc924ff2de",
        "collapsed": true,
        "_cell_guid": "ec43e6f6-51f7-4590-96d4-7e45bad659ec",
        "trusted": false
      },
      "cell_type": "code",
      "source": "'''\n## load model\n\n#print(dir_logs + ': ' + str(os.listdir(dir_logs)))\nprint('load '+ dir_logs + '/model.npz')\nnpzFile = np.load(dir_logs+'/model.npz');\n#print(npzFile.files);\nlearn_rate = npzFile['learn_rate'];\nkeep_prob = npzFile['keep_prob'];\nmb_size = npzFile['mb_size'];\nlog_step = npzFile['log_step'];\ntrain_loss = npzFile['train_loss'];\nval_loss = npzFile['val_loss'];\ntrain_acc = npzFile['train_acc'];\nval_acc = npzFile['val_acc'];\nval_loss_final = npzFile['val_loss_final'];\nval_acc_final = npzFile['val_acc_final'];\n\nsess = tf.InteractiveSession() # start TensorFlow session\n#sess.run(tf.global_variables_initializer()) # initialiue global variables\nW_conv1.load(npzFile['W_conv1'], session=sess)\nb_conv1.load(npzFile['b_conv1'], session=sess)\nW_conv2.load(npzFile['W_conv2'], session=sess)\nb_conv2.load(npzFile['b_conv2'], session=sess)\nW_fc1.load(npzFile['W_fc1'], session=sess)\nb_fc1.load(npzFile['b_fc1'], session=sess)\nW_fc2.load(npzFile['W_fc2'], session=sess)\nb_fc2.load(npzFile['b_fc2'], session=sess)\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "55718aab0eed2d5894f5df7764645c5c24f9f605",
        "collapsed": true,
        "_cell_guid": "083ed09c-7e93-49e5-ae28-eccc9282d20f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## confusion matrix\nif val_set_size > 0:\n    y_predict = sess.run(tf.argmax(y,1), feed_dict={x: val_images,tf_keep_prob: 1.0});\n    y_target = sess.run(tf.argmax(val_labels,1));\n    print('confusion matrix:')\n    print(sess.run(tf.contrib.metrics.confusion_matrix(predictions = y_predict, \n                                                       labels = y_target)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6541c6ca89fd856531b2f0280cbe78d91da87183",
        "collapsed": true,
        "_cell_guid": "7e351ab9-f9dc-41d1-80ee-802b1c8a9114",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## final loss, accuracy \n\nif val_set_size > 0:\n    val_loss_final = sess.run(cross_entropy, feed_dict={x: val_images,y_: val_labels, \n                                                        tf_keep_prob: 1.0});        \n    val_acc_final = accuracy.eval(feed_dict={x: val_images, y_: val_labels, tf_keep_prob: 1.0})\n    print('final: val_loss = %.4f, val_acc = %.4f'%(val_loss_final,val_acc_final))\n\nplt.figure(figsize=(10, 5));\nplt.subplot(1,2,1);\nplt.plot(np.arange(0,len(train_acc))*log_step*mb_size/train_set_size, train_acc,'-b', \n         label='Training')\nplt.plot(np.arange(0,len(val_acc))*log_step*mb_size/train_set_size, val_acc,'-g', \n         label='Validation')\nplt.legend(loc='lower right', frameon=False)\nplt.ylim(ymax = 1.1, ymin = 0.0)\nplt.ylabel('accuracy')\nplt.xlabel('epoch');\n\nplt.subplot(1,2,2)\nplt.plot(np.arange(0,len(train_loss))*log_step*mb_size/train_set_size, train_loss,'-b', \n         label='Training')\nplt.plot(np.arange(0,len(val_loss))*log_step*mb_size/train_set_size, val_loss,'-g', \n         label='Validation')\nplt.legend(loc='lower right', frameon=False)\nplt.ylim(ymax = 3.0, ymin = 0.0)\nplt.ylabel('loss')\nplt.xlabel('epoch');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5532356d3a392b9d76205c02cdc17d92fdfe2481",
        "collapsed": true,
        "_cell_guid": "add9e626-e259-4b3f-82ef-078778113782",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## visualize weights\n\nW_conv1_vis = W_conv1.eval();\nprint('W_conv1: min = ' + str(np.min(W_conv1_vis)) + ' max = ' + str(np.max(W_conv1_vis))\n      + ' mean = ' + str(np.mean(W_conv1_vis)) + ' std = ' + str(np.std(W_conv1_vis)))\nW_conv1_vis = np.reshape(W_conv1_vis,(s_f_conv1,s_f_conv1,1,6,6))\nW_conv1_vis = np.transpose(W_conv1_vis,(3,0,4,1,2))\nW_conv1_vis = np.reshape(W_conv1_vis,(s_f_conv1*6,s_f_conv1*6,1))\nplt.gca().set_xticks(np.arange(-0.5, s_f_conv1*6, s_f_conv1), minor = True);\nplt.gca().set_yticks(np.arange(-0.5, s_f_conv1*6, s_f_conv1), minor = True);\nplt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\nplt.title('W_conv1 ' + str(W_conv1.shape))\nplt.colorbar(plt.imshow(W_conv1_vis[:,:,0], cmap=cm.binary));\nplt.show();\n\nW_conv2_vis = W_conv2.eval();\nprint('W_conv2: min = ' + str(np.min(W_conv2_vis)) + ' max = ' + str(np.max(W_conv2_vis))\n      + ' mean = ' + str(np.mean(W_conv2_vis)) + ' std = ' + str(np.std(W_conv2_vis)))\nW_conv2_vis = np.reshape(W_conv2_vis,(s_f_conv2,s_f_conv2,6,6,36))\nW_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1,4))\nW_conv2_vis = np.reshape(W_conv2_vis,(6*s_f_conv2,6*s_f_conv2,6,6))\nW_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1))\nW_conv2_vis = np.reshape(W_conv2_vis,(6*6*s_f_conv2,6*6*s_f_conv2))\nplt.figure(figsize=(15,10))\nplt.gca().set_xticks(np.arange(-0.5, 6*6*s_f_conv2, 6*s_f_conv2), minor = True);\nplt.gca().set_yticks(np.arange(-0.5, 6*6*s_f_conv2, 6*s_f_conv2), minor = True);\nplt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\nplt.title('W_conv2 ' + str(W_conv2.shape))\nplt.colorbar(plt.imshow(W_conv2_vis[:,:], cmap=cm.binary));\n\nW_conv3_vis = W_conv3.eval();\nprint('W_conv3: min = ' + str(np.min(W_conv3_vis)) + ' max = ' + str(np.max(W_conv3_vis))\n      + ' mean = ' + str(np.mean(W_conv3_vis)) + ' std = ' + str(np.std(W_conv3_vis)))\nW_conv3_vis = np.reshape(W_conv3_vis,(s_f_conv3,s_f_conv3,6,6,36))\nW_conv3_vis = np.transpose(W_conv3_vis,(2,0,3,1,4))\nW_conv3_vis = np.reshape(W_conv3_vis,(6*s_f_conv3,6*s_f_conv3,6,6))\nW_conv3_vis = np.transpose(W_conv3_vis,(2,0,3,1))\nW_conv3_vis = np.reshape(W_conv3_vis,(6*6*s_f_conv3,6*6*s_f_conv3))\nplt.figure(figsize=(15,10))\nplt.gca().set_xticks(np.arange(-0.5, 6*6*s_f_conv3, 6*s_f_conv3), minor = True);\nplt.gca().set_yticks(np.arange(-0.5, 6*6*s_f_conv3, 6*s_f_conv3), minor = True);\nplt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\nplt.title('W_conv3 ' + str(W_conv3.shape))\nplt.colorbar(plt.imshow(W_conv3_vis[:,:], cmap=cm.binary));\n\n#b_conv1_vis = b_conv1.eval();\n#print('b_conv1 = ',b_conv1_vis)\n#b_conv2_vis = b_conv2.eval();\n#print('b_conv2 = ',b_conv2_vis)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f169ddac4c3639ba734f67048ba41b775d68094",
        "collapsed": true,
        "_cell_guid": "ab004898-a7ec-4e89-9be2-503db6e24d66",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## visualize activations\n\nIMG_NO = 10;\nfeed_dict = {x: train_images[IMG_NO:IMG_NO+1], tf_keep_prob: 1.0}\n\n# original image\nplt.figure(figsize=(15,10))\nplt.subplot(3,3,1)\nplt.title('prediction: %d'%predict.eval(feed_dict = feed_dict))\nplt.imshow(train_images[IMG_NO].reshape(image_width,image_height),cmap=cm.binary);\n\n# 1. convolution\nh_conv1_vis = h_conv1.eval(feed_dict = feed_dict);\nplt.subplot(3,3,2)\nplt.title('h_conv1 ' + str(h_conv1_vis.shape))\nh_conv1_vis = np.reshape(h_conv1_vis,(-1,28,28,6,6))\nh_conv1_vis = np.transpose(h_conv1_vis,(0,3,1,4,2))\nh_conv1_vis = np.reshape(h_conv1_vis,(-1,6*28,6*28))\nplt.imshow(h_conv1_vis[0], cmap=cm.binary);\n\n# 1. max pooling\nh_pool1_vis = h_pool1.eval(feed_dict = feed_dict);\nplt.subplot(3,3,3)\nplt.title('h_pool1 ' + str(h_pool1_vis.shape))\nh_pool1_vis = np.reshape(h_pool1_vis,(-1,14,14,6,6))\nh_pool1_vis = np.transpose(h_pool1_vis,(0,3,1,4,2))\nh_pool1_vis = np.reshape(h_pool1_vis,(-1,6*14,6*14))\nplt.imshow(h_pool1_vis[0], cmap=cm.binary);\n\n# 2. convolution\nh_conv2_vis = h_conv2.eval(feed_dict = feed_dict);\nplt.subplot(3,3,4)\nplt.title('h_conv2 ' + str(h_conv2_vis.shape))\nh_conv2_vis = np.reshape(h_conv2_vis,(-1,14,14,6,6))\nh_conv2_vis = np.transpose(h_conv2_vis,(0,3,1,4,2))\nh_conv2_vis = np.reshape(h_conv2_vis,(-1,6*14,6*14))\nplt.imshow(h_conv2_vis[0], cmap=cm.binary);\n\n# 2. max pooling\nh_pool2_vis = h_pool2.eval(feed_dict = feed_dict);\nplt.subplot(3,3,5)\nplt.title('h_pool2 ' + str(h_pool2_vis.shape))\nh_pool2_vis = np.reshape(h_pool2_vis,(-1,7,7,6,6))\nh_pool2_vis = np.transpose(h_pool2_vis,(0,3,1,4,2))\nh_pool2_vis = np.reshape(h_pool2_vis,(-1,6*7,6*7))\nplt.imshow(h_pool2_vis[0], cmap=cm.binary);\n\n# 3. convolution\nh_conv3_vis = h_conv3.eval(feed_dict = feed_dict);\nplt.subplot(3,3,6)\nplt.title('h_conv3 ' + str(h_conv3_vis.shape))\nh_conv3_vis = np.reshape(h_conv3_vis,(-1,7,7,6,6))\nh_conv3_vis = np.transpose(h_conv3_vis,(0,3,1,4,2))\nh_conv3_vis = np.reshape(h_conv3_vis,(-1,6*7,6*7))\nplt.imshow(h_conv3_vis[0], cmap=cm.binary);\n\n# 3. max pooling\nh_pool3_vis = h_pool3.eval(feed_dict = feed_dict);\nplt.subplot(3,3,7)\nplt.title('h_pool2 ' + str(h_pool3_vis.shape))\nh_pool3_vis = np.reshape(h_pool3_vis,(-1,4,4,6,6))\nh_pool3_vis = np.transpose(h_pool3_vis,(0,3,1,4,2))\nh_pool3_vis = np.reshape(h_pool3_vis,(-1,6*4,6*4))\nplt.imshow(h_pool3_vis[0], cmap=cm.binary);\n\n# 4. FC layer\nh_fc1_vis = h_fc1.eval(feed_dict = feed_dict);\nplt.subplot(3,3,8)\nplt.title('h_fc1 ' + str(h_fc1_vis.shape))\nh_fc1_vis = np.reshape(h_fc1_vis,(-1,24,24))\nplt.imshow(h_fc1_vis[0], cmap=cm.binary);\nplt.show()\n\n# 5. FC layer\nh_fc2_vis = y.eval(feed_dict = feed_dict);\nnp.set_printoptions(precision=2)\nprint('h_fc2 = ', h_fc2_vis)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aaa323f005713a891ab3a1faa7aa9549fd88ff30",
        "collapsed": true,
        "_cell_guid": "f7508494-8533-492d-8772-f14a99e35ade",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## show misclassified images\nif val_set_size > 0:\n    y_val_predict = sess.run(tf.argmax(y,1), feed_dict={x: val_images, tf_keep_prob: 1.0});\n    y_val_target = sess.run(tf.argmax(val_labels,1));\n    \n    y_val_false_index = []\n    for i in range(y_val_target.shape[0]):\n        if y_val_predict[i] != y_val_target[i]:\n            y_val_false_index.append(i)\n\n    print('# false predictions: ', len(y_val_false_index))\n\n    plt.figure(figsize=(10,15))\n    for j in range(0,5):\n        for i in range(0,10):\n            if j*10+i<len(y_val_false_index):\n                plt.subplot(10,10,j*10+i+1)\n                plt.title('%d/%d'%(y_val_target[y_val_false_index[j*10+i]],\n                                   y_val_predict[y_val_false_index[j*10+i]]))\n                plt.imshow(val_images[y_val_false_index[j*10+i]].reshape(28,28),cmap=cm.binary)    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "176c76821d5518569b5e33569dd127fd91039cc4",
        "_cell_guid": "069e66b4-fb6c-4a55-9dd0-5f0d23717388"
      },
      "cell_type": "markdown",
      "source": "## 5. Testing\n- predict and submit the results for the test set"
    },
    {
      "metadata": {
        "_uuid": "dd5c3638434505b4491ddd8c804bf53e9d20dfa6",
        "_cell_guid": "2286dd81-8199-44ab-a119-1f7d5470b757",
        "collapsed": true,
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# read test data from CSV file \nif os.path.isfile('../input/test.csv'):\n    test_data = pd.read_csv('../input/test.csv') # on kaggle \n    print('test.csv loaded: test_data{0}'.format(test_data.shape))\nelif os.path.isfile('data/test.csv'):\n    test_data = pd.read_csv('data/test.csv') # on local environment\n    print('test.csv loaded: test_data{0}'.format(test_data.shape))\nelse:\n    print('Error: test.csv not found')\n    \ntest_images = test_data.iloc[:,0:].values.reshape(-1,28,28,1) # (28000,28,28,1) array\ntest_images = test_images.astype(np.float)\ntest_images = np.multiply(test_images, 1.0 / 255.0) # convert from [0:255] => [0.0:1.0]\nprint('read: test_images{0}'.format(test_images.shape));\n\n# using batches is more resource efficient\npredicted_labels = np.zeros(test_images.shape[0])\nbatch_size = 1000;\nfor i in range(0,int(test_images.shape[0]/batch_size)):\n    predicted_labels[i*batch_size:(i+1)*batch_size] = predict.eval(\n        feed_dict={x: test_images[i*batch_size:(i+1)*batch_size], tf_keep_prob: 1.0})\nprint('compute predicted_labels({0})'.format(len(predicted_labels)))\n\n# save predictions\nnp.savetxt('submission.csv', \n           np.c_[range(1,len(test_images)+1),predicted_labels], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')\n\nprint('saved: submission.csv');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85b4ef639e68901b701d9281fcd65933f699c05a",
        "collapsed": true,
        "_cell_guid": "7689a5ba-fdd8-4dcd-ab67-23fc2e3bf0fa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# look at test images and predicted labels\nplt.figure(figsize=(10,15))\nfor j in range(0,5):\n    for i in range(0,10):\n        plt.subplot(10,10,j*10+i+1)\n        plt.title('%d'%predicted_labels[j*10+i])\n        plt.imshow(test_images[j*10+i].reshape(28,28),cmap=cm.binary)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1f39c8494c0e34ea4eecc5941a67c7f3a9443d11",
        "collapsed": true,
        "_cell_guid": "c906dec2-00ac-4c25-9b79-cdc5e1d6e496",
        "trusted": false
      },
      "cell_type": "code",
      "source": "sess.close()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}